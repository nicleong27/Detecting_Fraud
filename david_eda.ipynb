{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Detecting Data Fraud Case Study\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('/home/david/Documents/temp/data.json')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.acct_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fraud'] = np.where((df.acct_type == 'fraudster_event')\n",
    "                       | (df.acct_type == 'fraudster')\n",
    "                       | (df.acct_type == 'fraudster_att')\n",
    "                       , 1\n",
    "                       , 0\n",
    "                      )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fraud.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample\n",
    "df = df.groupby('fraud').apply(lambda x: x.sample(n=1293)).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fraud.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraud = df[df.fraud == 1]\n",
    "df_fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_true = df[df.fraud != 1]\n",
    "df_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.description.iloc[0] # use beautiful soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(df.description.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('p')[0].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for text in soup.find_all('p'):\n",
    "    texts.append(text.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2_str = ' '.join(texts)\n",
    "text2_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a function to convert description into string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_string(des):\n",
    "    \n",
    "    from bs4 import BeautifulSoup\n",
    "    import string, re\n",
    "    from num2words import num2words as n2w # may have to download this, terminal: pip3 install num2words\n",
    "    \n",
    "    soup = BeautifulSoup(des)\n",
    "    texts = []\n",
    "    for text in soup.find_all('p'): # gets all the words in paragraphs \n",
    "        texts.append(text.get_text())\n",
    "    texts = ' '.join(texts).lower() # joins sentences together into one long paragraphs\n",
    "    texts = texts.replace('$', 'dollar ') # change $ symbole to 'dollar'\n",
    "    texts = re.split(r'\\W+', texts) # keeps all the words and numbers only, drops all symbol characters \n",
    "    \n",
    "    new_words = []\n",
    "    for word in texts: \n",
    "        if word[-2:] == 'am' or word[-2:] == 'pm': # split am and pm from numbers\n",
    "            new_words.append(word[:-2]) \n",
    "            new_words.append(word[-2:])\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    \n",
    "    texts = new_words\n",
    "    \n",
    "    new_words = []\n",
    "    for word in texts:\n",
    "        if word.isdigit(): # changes numbers into words 200 becomes two hundred \n",
    "            new_words.append(n2w(int(word)))\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "            \n",
    "    texts = new_words\n",
    "    \n",
    "    new_words = []\n",
    "    for word in texts:\n",
    "        if ' ' in word:\n",
    "            new_words.extend(word.split(' '))\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    \n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_string(df.description.iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# text2 = to_string(df.description.iloc[2]).lower()\n",
    "# text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text2 = text2.replace('$', 'dollar ')\n",
    "# text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# words = re.split(r'\\W+', text2)\n",
    "# words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_words = []\n",
    "# for word in words:\n",
    "#     if word[-2:] == 'am' or word[-2:] == 'pm':\n",
    "#         new_words.append(word[:-2])\n",
    "#         new_words.append(word[-2:])\n",
    "#     else:\n",
    "#         new_words.append(word)\n",
    "# new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from num2words import num2words as n2w\n",
    "\n",
    "# new_words_text_only = []\n",
    "# for word in new_words:\n",
    "#     if word.isdigit():\n",
    "#         new_words_text_only.append(n2w(int(word)))\n",
    "#     else:\n",
    "#         new_words_text_only.append(word)\n",
    "# new_words_text_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_word_lst = []\n",
    "# for word in new_words_text_only:\n",
    "#     if ' ' in word:\n",
    "#         final_word_lst.extend(word.split(' '))\n",
    "#     else:\n",
    "#         final_word_lst.append(word)\n",
    "# final_word_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_only = ''.join(to_string(df.description.iloc[2]))\n",
    "string_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_dict = {}\n",
    "for letter in string_only:\n",
    "    if letter in letter_dict:\n",
    "        letter_dict[letter] += 1\n",
    "    else:\n",
    "        letter_dict[letter] = 1\n",
    "\n",
    "\n",
    "vals = []\n",
    "for x in letter_dict.values():\n",
    "    vals.append(x)\n",
    "\n",
    "\n",
    "first_vals_dict = {}\n",
    "for x in vals:\n",
    "    if int(str(x)[0]) in first_vals_dict:\n",
    "        first_vals_dict[int(str(x)[0])] += 1\n",
    "    else:\n",
    "        first_vals_dict[int(str(x)[0])] = 1\n",
    "\n",
    "sorted_firsts = sorted(first_vals_dict.items())\n",
    "sorted_firsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = [x[0] for x in sorted_firsts]\n",
    "y = [x[1] for x in sorted_firsts]\n",
    "print(x)\n",
    "print(y) # use this as a table to model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look up different ways to normalize: min, max\n",
    "# look up: log trap. area under the curve rules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x,y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_firsts = []\n",
    "for i in range(len(x)):\n",
    "    for itr in range(y[i]):\n",
    "        lst_firsts.append(x[i])\n",
    "lst_firsts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median(lst):\n",
    "    n = len(lst)\n",
    "    if n%2 == 0:\n",
    "        return round((lst[n//2 -1] + lst[n//2])/2, 1)\n",
    "    else: \n",
    "        return lst[n//2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median(lst_firsts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_string(df.description.iloc[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add 'desc_string' column of texts from description column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['desc_string'] = df.description.apply(to_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify non-english entries, pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_en(txt):\n",
    "#     try:\n",
    "#         return ld.detect(txt)!='en'\n",
    "#     except:\n",
    "#         return False\n",
    "\n",
    "# df_foreign = df[df['desc_string'].apply(is_en)]\n",
    "# df_foreign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate to English using googletrans library: pip install googletrans: https://py-googletrans.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = Translator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.desc_string.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "translations.detect(df.desc_string.iloc[0]).lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations.detect('i am typing in english').lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang(txt):\n",
    "    return translations.detect(txt).lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_eng(txt):\n",
    "    if translations.detect(txt).lang != 'en':\n",
    "        return translations.translate(txt, dest = 'en').text\n",
    "    else:\n",
    "        return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang('yo quero mucho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations.translate('yo quero mucho', dest = 'en').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_eng('yo quero mucho')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create language column that specify the language source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df['desc_lang'] = df.desc_string.apply(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.desc_lang.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['desc_eng'] = df.desc_string.apply(to_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.desc_lang != 'en']['desc_eng']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_eng(df.desc_eng.iloc[2521])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.desc_string.iloc[280]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words1 = to_string(df.description.iloc[2])\n",
    "words2 = to_string(df.description.iloc[3])\n",
    "words3 = to_string(df.description.iloc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lst = [words1\n",
    "            , words2\n",
    "            , words3\n",
    "           ]\n",
    "tf_model = TfidfVectorizer()\n",
    "vectors = tf_model.fit_transform(word_lst)\n",
    "vectors[0].T.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.desc_string.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following needs up to 55.5 gbs of memory!\n",
    "# this is the reson for downsampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = TfidfVectorizer()\n",
    "row_vectors = tf_model.fit_transform(df.desc_string)\n",
    "\n",
    "word_columns = tf_model.get_feature_names()\n",
    "\n",
    "dense = row_vectors.todense()\n",
    "\n",
    "dense_list = dense.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf = pd.DataFrame(dense_list, columns = word_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf = df_tfidf.assign(f = df.fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample to scramble \n",
    "df_tfidf = df_tfidf.sample(frac=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_tfidf.drop('f', axis=1)\n",
    "y = df_tfidf.f\n",
    "X_train, X_test, y_train, y_test = train_test_split(X\n",
    "                                                    , y\n",
    "                                                    , test_size = 0.25\n",
    "                                                    , random_state = 42\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators = 199\n",
    "                                  , bootstrap = True\n",
    "                                  , max_features = 'sqrt'\n",
    "                                 )\n",
    "\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = rf_model.predict(X_test)\n",
    "rf_probs = rf_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUC Score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_value = roc_auc_score(y_test, rf_probs)\n",
    "roc_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importances\n",
    "\n",
    "fi = pd.DataFrame({'word': list(X_train.columns)\n",
    "                   , 'importance': rf_model.feature_importances_\n",
    "                  }\n",
    "                 ).sort_values('importance', ascending = False)\n",
    "fi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Do: Need to Filter out Stop words, upsample, use cosine similarity (make a new column)\n",
    "# Word to vec, google algorithm \n",
    "# Any new descriptions will need to be vectorized, must be in the test set \n",
    "# class weight = balanced <-- use as hyperparameter \n",
    "# SMOTE method for upsampling \n",
    "# minimize false negatives (predicted non-frauds but are actually fraud) \n",
    "# check precision recall score, recall preferred (proportions of actual positives predicted)\n",
    "# F1 score (to maximize precision and recall scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Benford's Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "body_lengths_true = df_true.body_length.values\n",
    "int(str(body_lengths_true[1])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_lengths_true_first = [int(str(x)[0]) for x in body_lengths_true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(body_lengths_true_first)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('First Number')\n",
    "plt.title('Non-Fraud');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_lengths_fraud = df_fraud.body_length.values\n",
    "body_lengths_fraud_first = [int(str(x)[0]) for x in body_lengths_fraud]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(body_lengths_fraud_first)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('First Number')\n",
    "plt.title('Fraud');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class imbalance, do over or under sampling. \n",
    "# vectorize the words and then add body length to train model \n",
    "# use tf-idf, count vectorizer to train the model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
